import os
import weaviate
from langchain.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Weaviate

from langchain.chains import RetrievalQA
from langchain.llms import OpenAI


def createDemoIndex(client: weaviate.Client):
    print("Creating Document class...")

    # Define the Schema object to use `text-embedding-ada-002` on `title` and `content`, but skip it for `url`
    document_schema = {
        "class": "Document",
        "description": "Document after TextSplitter",
        "vectorizer": "text2vec-openai",
        "moduleConfig": {
            "text2vec-openai": {
                "model": "ada",
                "modelVersion": "002",
                "type": "text"
            }
        },
        "properties": [
            {
                "name": "page_content",
                "description": "chunk of the page",
                "dataType": ["string"]
            },
            {
                "name": "page_id",
                "description": "number of the document",
                "dataType": ["int"]
            },
            {
                "name": "metadata",
                "description": "autogenerated metadata",
                "dataType": ["object"],
                "nestedProperties": [
                    {"dataType": ["text"], "name": "source"}
                ],
                "moduleConfig": {"text2vec-openai": {"skip": True}}
            }]
    }
    client.schema.create_class(document_schema)


def initSchema(client: weaviate.Client):
    client.schema.delete_all()
    schema = client.schema.get()
    #print(schema)
    document_class = next((x for x in schema["classes"] if x["class"] == 'Document'), None)
    if document_class is not None:
        print("Document class found")
    else:
        createDemoIndex(client)


if __name__ == '__main__':
    ai_api_key = os.environ["OPENAI_API_KEY"]
    print(ai_api_key)
    client = weaviate.Client(url="http://localhost:8080",
                             additional_headers={"X-OpenAI-Api-Key": ai_api_key})
    module_metadata = client.get_meta()
    # print(module_metadata)
    print(f"\nweaviate client isReady: {client.is_ready()} ")
    initSchema(client=client)
    loader = TextLoader("mediumblogs/mediumblogs.txt")
    document = loader.load()

    text_splitter = CharacterTextSplitter(chunk_size=700, chunk_overlap=200)
    texts = text_splitter.split_documents(document)
    print(len(texts))
    counter = 1

    with client.batch as batch:
        for text in texts:
            print(f"\n\n\n{text}")
            properties = {
                "page_content": text.page_content,
                "metadata": text.metadata,
                "page_id": counter
            }
            batch.add_data_object(properties, "Document")
            counter = counter + 1
    print("Documents import complete")

    exit(0)
    embeddings = OpenAIEmbeddings(openai_api_key=ai_api_key)

    vectorstore = Weaviate.from_documents(texts, embeddings, index_name="Document")

    qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type="stuff", retriever=vectorstore.as_retriever())

    res = qa.run("Give me the gist of Vector database in 3 sentences ")
    print(res)

    # vectorstore = FAISS.from_documents(texts, embeddings)
    # vectorstore.save_local("faiss_index_react")
    #
    # new_vectorstore = FAISS.load_local("faiss_index_react", embeddings)
    #
    # qa = RetrievalQA.from_chain_type(llm= OpenAI(), chain_type="stuff", retriever = new_vectorstore.as_retriever())
    #
    # res = qa.run("Give me the gist of Vector database in 3 sentences ")
    # print(res)
